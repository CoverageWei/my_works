1、 数据库软件是如何运行
	早期：数据是与应用程序一起进行编写
		数据的操作需要程序员自己完成
	人类社会第一次飞跃？社会化大分工
	数据库管理系统的诞生
		MySQL
		SQLServer
		SQLite
		等。。。
2、 数据库的基本概念

网站架构的演变：
->单主机服务器
-> 缓存服务器
	页面缓存
	数据缓存
-> 服务器集群
	请求 ——> Nginx等代理服务器 ——> 数据分发到web服务器集群的机器去【按照一定的策略】
-> 数据库分库
	【问题】
		1、访问哪一个数据库？
		2、如何保持数据同步？
		【原因】数据库1有的数据，数据库2可能没有，则写数据时访问数据库1，很可能下一次读访问的就是数据库2，会造成错误；
	【解决策略】主从复制：主数据库写完数据之后，将数据同步到从数据库中去；
	【问题】什么时候同步，数据库同步以后又如何访问，这个同步数据库之间是如何组织？

-> 分布式数据库

影响数据库性能的常见因素：
-> 读写竞争
-> 事务竞争
-> 频繁的事务处理

3、 数据库需要保证数据的准确与安全，提出来事务(transaction)的概念
	“事务”并非是数据库独有
	-> 银行转账
		z0001		10
		z0002		100
	从z0001中转入z0002中100块钱？
		update tbl set balance=balance-100 where id='z0001'	-- 报错
		update tbl set balance=balance+100 where id='z0002'	-- 正确执行
	条件(除非是信用账户)
		我们的余额不能小于0
	-> 严格的定义：
		满足原子性、一致性、持久性和隔离性的操作称为事物
	-> 隔离性会影响到数据的性能
		需要读取id为100的数据
		修改id为90-110的数据
	-> 隔离级别的概念
		未提交读：读取到刚刚修改的数据，但是数据库还没有同步该数据
				(脏读)
		已提交读：等待
		可重复读：等待
		序列化读：等待
	-> 共享锁和排它锁
	-> 死锁
		事务1
			先读取结果
			根据结果修改值
		事务2
			修改某一些数据
			查询最后的结果

	读写分离

4、数据库应用的分类
	-> 联机事务处理（OLTP）：增删改
	-> 联机事务分析（OLAP）：查

			
主从架构的原理：
	如何提高性能？—— 分库
		数据库要同步，不能出现两个或多个版本的数据
		还要保证数据的可用性
	【注意】二进制日志是专门用来记录数据库操作的，可以记录下数据库的每一个动作；
	主数据库的二进制日志可以分发到从数据库中【通过网络或Socket通信完成】，从数据库中得到的相应日志叫做中继日志【其实就是二进制日志的副本】；从数据库读取中继日志，然后通过执行中继日志，将执行结果同步到从数据库中；

	写操作————>主服务器，其他操作————>从服务器；
	单主多从，多主多从	———— 需要服务器路由
	1、多主服务器之间：Master-Master
		都是主服务器，但也存在着对等的主从关系；
		【Master-Master】复制的两台服务器，既是master，又是另一台服务器的slave。这样，任何一方所做的变更，都会通过复制应用到另外一方的数据库中。
		【过程】在主服务器A上执行写操作，会相应产生一个二进制日志A；相应地，需要将A的二进制日志传递给主服务器B作为中继日志，B执行中继日志导进结果，但是在这一过程B也会产生二进制日志B，也需要将B的二进制日志传递给A去执行...如何避免这种执行？
		【问题】循环复制？？更新冲突？？
		【解决】使用黑洞存储引擎
		【结论】多主之间数据是相同的
	
	2、多从服务器之间：Master-Slaves-Slaves
		一个高性能从服务器X + 多个普通从服务器
		【过程】高性能的从服务器接收主服务器传来的二进制日志作为自己的中继日志，执行并同步结果；相应地,X也会产生自己的二进制日志，并将这个二进制日志分发其它普通的从服务器；
		主服务器 ————> 高性能从服务器 ————> 其它普通从服务器
		【分析】真正执行读操作的服务器是这些普通从服务器

	web请求————> 按操作路由 
						写操作：主服务器
						读操作：从服务器
【好处】多线程查询无需等待，而且多个数据库同时执行；
	高可用性，容灾：一旦主服务器宕机，可以直接将高性能从服务器作为主服务器来使用，再从从服务器中找出一个替代高性能从服务器；
	数据副本：提高查询速度；
	主从有延时，数据会有误差：通过判断日志来解决
	不允许用户对从服务器进行写操作，只允许读操作，所以可以保证从服务器里面要么有正确的数据，要么读不到数据，但是绝对不会出错，可以保证正确性；

【总结】
	在实际应用场景中，MySQL复制90%以上都是一个Master复制到一个或者多个Slave的架构模式，主要用于【读压力】比较大的应用的数据库端廉价扩展解决方案。因为只要Master和Slave的压力不是太大（尤其是Slave端压力）的话，异步复制的延时一般都很少很少。尤其是自从Slave端的复制方式改成两个线程处理之后，更是减小了Slave端的延时问题。对于数据实时性要求不是特别Critical的应用，只需要通过廉价的pcserver来扩展Slave的数量，将读压力分散到多台Slave的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。
	一些建议：
	(1) 不同的slave扮演不同的作用(例如使用不同的索引，或者不同的存储引擎)；
	(2) 用一个slave作为备用master，只进行复制；
	(3) 用一个远程的slave，用于灾难恢复；



5、 配置的步骤
	-> 先配置master服务器
		-> 下载MySQL(安装，使用压缩文件)
		-> 修改配置文件(windows下是my.ini)
			开启二进制日志
			log-bin=master-bin
			使用二进制索引
			log-bin-index=master.bin.index
			设置服务器id(唯一)
			server-id=1
		-> 启动MySQL的服务
			>命令名字 --install 服务名字 --default-file="配置文件"
			>mysqld.exe --install MySQL0930 --default-file="my文件的路径" 
		-> 登录root账户
			>mysql -u root -p
			登录
			mysql> create user jk;
			添加用户的权限
			mysql> grant replication slave on *.*
					to jk identitified by '密码';
	
1、搭两台服务器
2、安装软件
3、根据脚本配置一下
	

Nginx：
反向代理服务器软件，Nginx本身就可以托管网站，进行HTTP服务处理，也可以作为反向代理服务器使用。
解决高并发：请求分发到不同服务器进行处理，降低服务器负载压力；
请求 ——> Nginx等代理服务器 ——> 数据分发到web服务器集群的机器去【按照一定的策略】


【正向代理】 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 
客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。
【反向代理】正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端。
在反向代理中，用户则始终认为它访问的是原始服务器而不是代理服务器；


特点：跨平台，非阻塞、高并发连接，事件驱动...
事件驱动：通信机制采用epoll模型，支持更大的并发连接

【阻塞调用】的方式，当读写事件没有准备好时，必然不能够进行读写事件，那么久只好等待，等事件准备好了，才能进行读写事件。
【非阻塞】通过不断检查事件的状态来判断是否进行读写操作，这样带来的开销很大；
【异步非阻塞的事件处理】提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。
	比如epoll模型：
	当事件没有准备好时，就放入epoll(队列)里面。如果有事件准备好了，那么就去处理；如果事件返回的是EAGAIN，那么继续将其放入epoll里面。从而，只要有事件准备好了，我们就去处理她，只有当所有时间都没有准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。 
【与多线程的比较：】
	与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。

【原理】通过异步非阻塞的事件处理机制，Nginx实现由进程循环处理多个准备好的事件，从而实现高并发和轻量级。 


1、Nginx配置IIS服务器列表；
2、一个网站部署到多台IIS服务器上；
3、请求访问Nginx，Nginx会根据访问地址将其定位到配置文件中维持的IIS服务器列表中的一个；

【负载均衡】技术在现有网络结构之上提供了一种廉价、有效、透明的方法，来扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。它有两方面的含义：首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间；其次，单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高 
